/**
 * Call Manager - Gerencia o fluxo completo de chamadas com IA
 */

const AudioSocketServer = require('./audiosocket-server');
const GroqService = require('./services/groq-service');
const ElevenLabsService = require('./services/elevenlabs-service');
const OpenRouterService = require('./services/openrouter-service');
const fs = require('fs');
const path = require('path');

class CallManager {
  constructor(config) {
    this.config = config;

    // Inicializa servi√ßos
    this.audioServer = new AudioSocketServer(
      config.audioSocket.host,
      config.audioSocket.port
    );

    this.groqService = new GroqService(config.groq.apiKey);
    this.elevenLabsService = new ElevenLabsService(config.elevenLabs.apiKey);
    this.openRouterService = new OpenRouterService(
      config.openRouter.apiKey,
      config.openRouter.model
    );

    // Estado das sess√µes
    this.sessions = new Map();

    // Carrega √°udio pr√©-gravado da sauda√ß√£o
    this.greetingAudio = null;
    this.loadGreetingAudio();

    this.setupEventHandlers();
  }

  loadGreetingAudio() {
    try {
      const greetingPath = path.join(__dirname, '..', 'greeting.pcm');
      if (fs.existsSync(greetingPath)) {
        this.greetingAudio = fs.readFileSync(greetingPath);
        console.log(`‚úÖ √Åudio de sauda√ß√£o carregado: ${this.greetingAudio.length} bytes`);
      } else {
        console.log('‚ö†Ô∏è  Arquivo greeting.pcm n√£o encontrado');
      }
    } catch (error) {
      console.error('‚ùå Erro ao carregar √°udio de sauda√ß√£o:', error.message);
    }
  }

  setupEventHandlers() {
    // Nova chamada iniciada
    this.audioServer.on('callStarted', (sessionId, session) => {
      console.log('\nüìû ============ NOVA CHAMADA ============');
      console.log('Session ID:', sessionId);

      // Inicializa estado da sess√£o
      this.sessions.set(sessionId, {
        audioBuffer: Buffer.alloc(0),
        lastSpeechTime: Date.now(),
        lastHighEnergyTime: null,
        isSpeaking: false,
        isProcessing: false,
        conversationStarted: false,
        isSendingGreeting: false,
        isSendingResponse: false
      });
    });

    // Handshake completado - pode enviar √°udio
    this.audioServer.on('handshakeComplete', (sessionId) => {
      console.log('‚úÖ Handshake completado - enviando sauda√ß√£o...');
      this.sendGreeting(sessionId);
    });

    // Frame de √°udio recebido
    this.audioServer.on('audioFrame', (sessionId, frame) => {
      const session = this.sessions.get(sessionId);

      // Ignora √°udio enquanto IA est√° falando (evita echo)
      if (session && (session.isSendingGreeting || session.isSendingResponse)) {
        return;
      }

      // Processa com IA
      this.handleAudioFrame(sessionId, frame);
    });

    // Chamada encerrada
    this.audioServer.on('callEnded', (sessionId) => {
      console.log('üìû ============ CHAMADA ENCERRADA ============');
      console.log('Session ID:', sessionId);

      // Limpa recursos
      this.openRouterService.resetConversation(sessionId);
      this.sessions.delete(sessionId);
    });
  }

  async handleAudioFrame(sessionId, frame) {
    const session = this.sessions.get(sessionId);
    if (!session || session.isProcessing) return;

    // Calcula energia do frame para detectar fala
    const energy = this.calculateAudioEnergy(frame);
    const SPEECH_ENERGY_THRESHOLD = 40; // Threshold para detectar fala
    const SILENCE_TOLERANCE_MS = 700;   // Continua capturando por 700ms ap√≥s fala parar

    const now = Date.now();

    // Detecta se h√° fala neste frame
    const hasSpeech = energy > SPEECH_ENERGY_THRESHOLD;

    if (hasSpeech) {
      // Fala detectada - atualiza timestamp
      session.lastHighEnergyTime = now;
    }

    // Calcula h√° quanto tempo n√£o detectamos fala
    const timeSinceHighEnergy = session.lastHighEnergyTime
      ? now - session.lastHighEnergyTime
      : Infinity;

    // Captura frame SE:
    // 1. Houver fala agora OU
    // 2. Detectamos fala recentemente (dentro da toler√¢ncia) E j√° estamos capturando
    const shouldCapture = hasSpeech ||
                          (session.lastHighEnergyTime &&
                           timeSinceHighEnergy < SILENCE_TOLERANCE_MS &&
                           session.audioBuffer.length > 0);

    if (shouldCapture) {
      session.audioBuffer = Buffer.concat([session.audioBuffer, frame]);
      session.lastSpeechTime = now;

      // Log para debug (a cada 200ms)
      if (session.audioBuffer.length % 3200 === 0) {
        console.log(`üéôÔ∏è  Capturando... ${(session.audioBuffer.length / 16000).toFixed(1)}s (energia: ${energy.toFixed(1)})`);
      }
    }

    // Processa quando tiver 2-3 segundos de fala
    const PROCESS_THRESHOLD = 20000; // 2.5 segundos

    if (session.audioBuffer.length >= PROCESS_THRESHOLD) {
      await this.processAudio(sessionId);
    }

    // Timeout: se passou 1s desde √∫ltima fala forte e tem algo no buffer, processa
    if (session.audioBuffer.length > 8000 && // Min 0.5s de fala
        timeSinceHighEnergy > 1000) {         // 1s de sil√™ncio ap√≥s fala
      console.log(`‚è±Ô∏è  Fim de fala detectado (${(session.audioBuffer.length / 16000).toFixed(1)}s) - processando...`);
      await this.processAudio(sessionId);
    }
  }

  calculateAudioEnergy(pcmBuffer) {
    // Calcula RMS (Root Mean Square) do √°udio PCM 16-bit
    let sum = 0;
    for (let i = 0; i < pcmBuffer.length; i += 2) {
      // L√™ sample de 16-bit little-endian
      const sample = pcmBuffer.readInt16LE(i);
      sum += sample * sample;
    }
    const rms = Math.sqrt(sum / (pcmBuffer.length / 2));
    return rms;
  }

  async processAudio(sessionId) {
    const session = this.sessions.get(sessionId);
    if (!session || session.isProcessing) return;

    session.isProcessing = true;
    const audioToProcess = session.audioBuffer;
    session.audioBuffer = Buffer.alloc(0);

    // Removido envio de sil√™ncio - deixa o Asterisk aguardar

    try {
      // Converte PCM para WAV
      const wavBuffer = this.pcmToWav(audioToProcess);

      // STT: √Åudio ‚Üí Texto (usando Groq Whisper)
      console.log('üé§ Transcrevendo √°udio...');
      const userText = await this.groqService.speechToText(wavBuffer);

      if (!userText || userText.trim().length === 0) {
        console.log('‚ö†Ô∏è  Nenhum texto detectado');
        session.isProcessing = false;
        return;
      }

      console.log('üë§ Usu√°rio disse:', userText);

      // IA: Texto ‚Üí Resposta (usando OpenRouter)
      const aiResponse = await this.openRouterService.chat(sessionId, userText);

      // TTS: Resposta ‚Üí √Åudio (usando Eleven Labs)
      console.log('üó£Ô∏è  Gerando resposta em √°udio...');
      const responseAudio = await this.elevenLabsService.textToSpeech(aiResponse);

      // Envia √°udio de volta para o Asterisk
      if (responseAudio.length > 0) {
        console.log('üì° Enviando √°udio para Asterisk...');

        // Marca que est√° enviando resposta (ignora √°udio recebido para evitar echo)
        session.isSendingResponse = true;

        this.audioServer.stopSilence(sessionId);
        await this.audioServer.sendAudio(sessionId, responseAudio);

        // Terminou de enviar resposta
        if (this.sessions.has(sessionId)) {
          session.isSendingResponse = false;
          // Limpa buffer para n√£o processar √°udio capturado durante resposta
          session.audioBuffer = Buffer.alloc(0);
          console.log('‚úÖ Resposta enviada - aguardando cliente falar...');
        }
      }

    } catch (error) {
      console.error('‚ùå Erro ao processar √°udio:', error.message);
      if (session) {
        session.isSendingResponse = false;
      }
    }

    session.isProcessing = false;
  }

  async sendGreeting(sessionId) {
    const session = this.sessions.get(sessionId);

    // Verifica se a sess√£o ainda existe
    if (!session) {
      console.log('‚ö†Ô∏è  Sess√£o encerrada antes da sauda√ß√£o');
      return;
    }

    try {
      console.log('üëã Enviando sauda√ß√£o pr√©-gravada...');

      // Marca que est√° enviando sauda√ß√£o (para ignorar √°udio recebido)
      session.isSendingGreeting = true;

      // Define prompt do sistema para vendas de precat√≥rios
      this.openRouterService.setSystemPrompt(sessionId, `Voc√™ √© um assistente de IA da Addebitare fazendo uma liga√ß√£o para comprar precat√≥rios.

Seu objetivo √©:
- Confirmar se a pessoa tem precat√≥rios para vender
- Qualificar o precat√≥rio (valor, tribunal, estado)
- Agendar uma proposta comercial
- Ser educado e profissional
- Fazer perguntas diretas e objetivas

Importante:
- Sempre responda em portugu√™s do Brasil
- Mantenha as respostas curtas (m√°ximo 30 palavras)
- Seja natural e conversacional
- N√£o use emojis ou s√≠mbolos especiais
- Se a pessoa disser que n√£o tem precat√≥rios, agrade√ßa e encerre educadamente`);

      // Envia √°udio pr√©-gravado imediatamente (em frames de 20ms)
      if (this.greetingAudio && this.sessions.has(sessionId)) {
        await this.audioServer.sendAudio(sessionId, this.greetingAudio);
        console.log('‚úÖ Sauda√ß√£o completa enviada - aguardando resposta do cliente...');

        // Marca que terminou de enviar (agora pode processar √°udio)
        if (this.sessions.has(sessionId)) {
          session.isSendingGreeting = false;
          // Limpa buffer de √°udio que possa ter acumulado
          session.audioBuffer = Buffer.alloc(0);
        }
      } else if (!this.greetingAudio) {
        console.log('‚ö†Ô∏è  √Åudio de sauda√ß√£o n√£o dispon√≠vel');
        session.isSendingGreeting = false;
      }

    } catch (error) {
      console.error('‚ùå Erro ao enviar sauda√ß√£o:', error.message);
      if (session) {
        session.isSendingGreeting = false;
      }
    }
  }

  pcmToWav(pcmData) {
    const sampleRate = 8000;
    const numChannels = 1;
    const bitsPerSample = 16;
    const byteRate = sampleRate * numChannels * (bitsPerSample / 8);
    const blockAlign = numChannels * (bitsPerSample / 8);
    const dataSize = pcmData.length;

    const header = Buffer.alloc(44);

    // RIFF header
    header.write('RIFF', 0);
    header.writeUInt32LE(36 + dataSize, 4);
    header.write('WAVE', 8);

    // fmt chunk
    header.write('fmt ', 12);
    header.writeUInt32LE(16, 16);
    header.writeUInt16LE(1, 20); // PCM
    header.writeUInt16LE(numChannels, 22);
    header.writeUInt32LE(sampleRate, 24);
    header.writeUInt32LE(byteRate, 28);
    header.writeUInt16LE(blockAlign, 32);
    header.writeUInt16LE(bitsPerSample, 34);

    // data chunk
    header.write('data', 36);
    header.writeUInt32LE(dataSize, 40);

    return Buffer.concat([header, pcmData]);
  }

  start() {
    console.log('\nüöÄ ============ LigAI Iniciando ============');
    console.log('üì° AudioSocket:', `${this.config.audioSocket.host}:${this.config.audioSocket.port}`);
    console.log('ü§ñ IA Model:', this.config.openRouter.model);
    console.log('==========================================\n');

    this.audioServer.start();
  }

  stop() {
    this.audioServer.stop();
    console.log('üõë LigAI parado');
  }
}

module.exports = CallManager;
