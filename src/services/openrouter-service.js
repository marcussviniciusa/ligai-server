/**
 * OpenRouter Service - IA/LLM para processar conversas
 */

const { OpenAI } = require('openai');

class OpenRouterService {
  constructor(apiKey, model = 'anthropic/claude-3.5-sonnet') {
    this.client = new OpenAI({
      baseURL: 'https://openrouter.ai/api/v1',
      apiKey: apiKey,
      defaultHeaders: {
        'HTTP-Referer': 'https://ligai.app',
        'X-Title': 'LigAI - Sistema de IA de Liga√ß√µes'
      }
    });
    this.model = model;
    this.conversationHistory = new Map();
  }

  /**
   * Processa mensagem do usu√°rio e retorna resposta da IA
   * @param {string} sessionId - ID da sess√£o
   * @param {string} userMessage - Mensagem do usu√°rio
   * @param {object} systemPrompt - Prompt do sistema (opcional)
   * @returns {Promise<string>} Resposta da IA
   */
  async chat(sessionId, userMessage, systemPrompt = null) {
    try {
      // Inicializa hist√≥rico da conversa se n√£o existir
      if (!this.conversationHistory.has(sessionId)) {
        const initialMessages = [];

        if (systemPrompt) {
          initialMessages.push({
            role: 'system',
            content: systemPrompt
          });
        } else {
          // Prompt padr√£o para vendas/atendimento
          initialMessages.push({
            role: 'system',
            content: `Voc√™ √© um assistente de IA amig√°vel fazendo uma liga√ß√£o telef√¥nica.

Seu objetivo √©:
- Ser educado e profissional
- Fazer perguntas diretas e objetivas
- Ouvir atentamente as respostas
- N√£o ser muito verboso (respostas curtas de 1-2 frases)
- Adaptar-se ao tom da conversa

Importante:
- Sempre responda em portugu√™s do Brasil
- Mantenha as respostas curtas (m√°ximo 30 palavras)
- Seja natural e conversacional
- N√£o use emojis ou s√≠mbolos especiais`
          });
        }

        this.conversationHistory.set(sessionId, initialMessages);
      }

      // Adiciona mensagem do usu√°rio
      const history = this.conversationHistory.get(sessionId);
      history.push({
        role: 'user',
        content: userMessage
      });

      console.log('ü§ñ Processando com IA:', userMessage);

      // Chama OpenRouter
      const response = await this.client.chat.completions.create({
        model: this.model,
        messages: history,
        temperature: 0.7,
        max_tokens: 150,
        top_p: 1,
        frequency_penalty: 0,
        presence_penalty: 0
      });

      const aiResponse = response.choices[0].message.content;

      // Adiciona resposta ao hist√≥rico
      history.push({
        role: 'assistant',
        content: aiResponse
      });

      // Limita hist√≥rico a √∫ltimas 10 mensagens
      if (history.length > 12) {
        // Mant√©m system prompt + √∫ltimas 10 mensagens
        const systemMsg = history[0];
        const recentMessages = history.slice(-10);
        this.conversationHistory.set(sessionId, [systemMsg, ...recentMessages]);
      }

      console.log('ü§ñ Resposta da IA:', aiResponse);
      return aiResponse;

    } catch (error) {
      console.error('‚ùå Erro no OpenRouter:', error.message);
      return 'Desculpe, estou tendo problemas t√©cnicos. Pode repetir?';
    }
  }

  /**
   * Reset do hist√≥rico de conversa
   */
  resetConversation(sessionId) {
    this.conversationHistory.delete(sessionId);
    console.log('üîÑ Hist√≥rico resetado para sess√£o:', sessionId);
  }

  /**
   * Define um prompt customizado para a sess√£o
   */
  setSystemPrompt(sessionId, promptText) {
    const messages = [{
      role: 'system',
      content: promptText
    }];
    this.conversationHistory.set(sessionId, messages);
  }
}

module.exports = OpenRouterService;
